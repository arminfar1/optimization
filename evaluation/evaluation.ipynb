{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6b91da",
   "metadata": {},
   "source": [
    "### This notebook is for testing model recommendation with the prepared testing dataset\n",
    "### The model imported is expected to be on hybrid level with column names as follows\n",
    "### ['origin', 'destination', 'ship method', 'wh_ind', 'pad'] where the origin can be either warehouse id (wh_ind =1) or origin zip3 (wh_ind = 0), destination can be destination zip3 for 3p shipments and hard-coded 'SWA_DEST' for 1p shipments, 'pad' is the model output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feac4aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f923a46b-3adb-48d1-8a85-a98923dab731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def schedule_adjust(test_data_input):\n",
    "    \n",
    "    test_data = test_data_input.copy()\n",
    "    test_data.loc[test_data['pad'] == 0, 'adjusted_pad'] = 0\n",
    "    \n",
    "    ### positive and negative pad\n",
    "    ## mon-fri delivery\n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=4), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=4), 'pad']\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >4), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >4), 'pad'] + 2\n",
    "    test_data.loc[\n",
    "              (test_data['pad'] >0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([5])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[\n",
    "                (test_data['pad'] >0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([5])) , 'pad'] + 1\n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])) , 'pad'] \n",
    "    # negative pads\n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >= 0), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >= 0), 'pad']\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] < 0), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] < 0), 'pad'] - 2\n",
    "    \n",
    "    test_data.loc[\n",
    "              (test_data['pad'] <0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([5])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[\n",
    "                (test_data['pad'] <0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([5])) , 'pad'] \n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])) , 'pad'] - 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # mon-sun delivery\n",
    "    test_data.loc[(test_data['pad'].notnull())        \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'] == 'Y'), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'].notnull())        \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'] == 'Y'), 'pad'] \n",
    "    \n",
    "        # mon-sat delivery\n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >5), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >5), 'pad'] + 1\n",
    "    \n",
    "    test_data.loc[\n",
    "              (test_data['pad'] >0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=5), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=5), 'pad'] \n",
    "    \n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])), 'pad'] \n",
    "    \n",
    "    # negative pads\n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >=0), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >=0), 'pad'] \n",
    "    \n",
    "    test_data.loc[\n",
    "              (test_data['pad'] <0) \n",
    "              &(test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <0), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <0), 'pad'] - 1\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'] == 'Y') \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])), 'pad'] \n",
    "    \n",
    "    # tu-sat delivery\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              &(test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >5), 'adjusted_pad'] \\\n",
    "    = test_data.loc[\n",
    "              (test_data['pad'] >0) \n",
    "              &(test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >5), 'pad'] + 2\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=5), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=5), 'pad'] \n",
    "    \n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              &(test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])), 'pad'] + 1\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0])), 'pad'] \n",
    "    # negative pads\n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              &(test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >=1), 'adjusted_pad'] \\\n",
    "    = test_data.loc[\n",
    "              (test_data['pad'] <0) \n",
    "              &(test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >=1), 'pad'] \n",
    "    \n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <1), 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <1), 'pad'] - 2\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              &(test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([6])), 'pad'] \n",
    "    \n",
    "    test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0])) , 'adjusted_pad'] \\\n",
    "    = test_data.loc[(test_data['pad'] <0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'] == 'Y') \n",
    "              & (test_data['wed'] == 'Y')\n",
    "              & (test_data['th'] == 'Y')\n",
    "              & (test_data['fri'] == 'Y')\n",
    "              & (test_data['sat'] == 'Y')\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0])), 'pad'] - 1\n",
    "    \n",
    "    \n",
    "    # sat delivery only\n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'].isnull()) \n",
    "              & (test_data['wed'].isnull())\n",
    "              & (test_data['th'].isnull())\n",
    "              & (test_data['fri'].isnull())\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=5), 'adjusted_pad']\\\n",
    "    = 5 - test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'].isnull()) \n",
    "              & (test_data['wed'].isnull())\n",
    "              & (test_data['th'].isnull())\n",
    "              & (test_data['fri'].isnull())\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] <=5), 'unpadded_pdd_dayofweek']\n",
    "    \n",
    "    test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'].isnull()) \n",
    "              & (test_data['wed'].isnull())\n",
    "              & (test_data['th'].isnull())\n",
    "              & (test_data['fri'].isnull())\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >5), 'adjusted_pad'] \\\n",
    "    = 12 - test_data.loc[(test_data['pad'] >0) \n",
    "              & (test_data['mon'].isnull()) \n",
    "              & (test_data['tu'].isnull()) \n",
    "              & (test_data['wed'].isnull())\n",
    "              & (test_data['th'].isnull())\n",
    "              & (test_data['fri'].isnull())\n",
    "              & (test_data['sat'].isnull())\n",
    "              & (test_data['sun'].isnull())\n",
    "              & (test_data['unpadded_pdd_dayofweek'].isin([0,1,2,3,4,5])) \n",
    "              & (test_data['unpadded_pdd_dayofweek'] + test_data['pad'] >5), 'unpadded_pdd_dayofweek']    \n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957b3257-7dc5-4336-a573-62c88936e54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Testing \n",
    "def ReadTestData(date):\n",
    "     \n",
    "    data = pd.read_csv('s3://df-datascience-adhoc/Adhoc/data/xinxiong/test/tt_pad_test_shipments_{}.csv000'.format(date))\n",
    "    data.columns =['region_id', 'marketplace_id', 'shipment_id', 'tracking_id',\n",
    "                   'warehouse_id', 'carrier', 'ship_method_orig', 'ship_method', 'origin_zip3', 'destination_zip3', \n",
    "                   'origin_zip5', 'destination_zip5',\n",
    "                   'order_datetime','of_datetime', 'is_fasttrack', \n",
    "                   'c2exsd', 'c2p_days', 'c2p_days_unpadded', 'c2d_days', 'att_c2d_days',\n",
    "                   'att_failed_pdd', 'no_att_scan', 'unpadded_pdd_date', 'tt_pad', 'gl_group',\n",
    "                   'att_del_datetime', 'c2p_hours_unpadded', 'c2p_hours', 'c2d_hours',\n",
    "                   'mon', 'tu', 'wed', 'th', 'fri', 'sat', 'sun', 'gl_label', 'amazon_parent_ship_method',\n",
    "                   ]\n",
    "    data['warehouse_id'] = data['warehouse_id'].astype('str')\n",
    "    data['origin_zip3'] = data['origin_zip3'].fillna(0).astype('int').astype('str').str.zfill(3) \n",
    "    data['destination_zip3'] = data['destination_zip3'].fillna(0).astype('int').astype('str').str.zfill(3) \n",
    "    \n",
    "    #data['origin_zip5'] = data['origin_zip5'].fillna(0).astype('int').astype('str').str.zfill(5) \n",
    "    #data['destination_zip5'] = data['destination_zip5'].fillna(0).astype('int').astype('str').str.zfill(5)\n",
    "    \n",
    "    data = data[(data['c2p_hours']>=0) & (data['c2p_days']>=0)].copy()\n",
    "    ship_method_list  = ['UPS_GROUND','SWA','UPS_2ND_DAY','UPS_NEXT_DAY']\n",
    "    data = data[data['ship_method'].isin(ship_method_list)]\n",
    "\n",
    "    print(\"Test data shape is: \", data.shape)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4272e02c-002f-40f1-b299-2a3e0f9b2dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " def apply_pads(test_data, model_output):\n",
    "    pad_dict = {}\n",
    "    for idx, row in model_output.iterrows():\n",
    "        if row['ship_method'] == \"SWA\":\n",
    "            key = (row['origin'], row['ship_method'])\n",
    "        else:\n",
    "            key = (row['origin'], row['destination_zip3'], row['ship_method'])\n",
    "\n",
    "        pad_dict[key] = row['pad']\n",
    "\n",
    "    def get_pad(row):\n",
    "        if row['ship_method'] == \"SWA\":\n",
    "            key = (row['warehouse_id'], row['ship_method'])\n",
    "            return pad_dict.get(key, None)\n",
    "        else:\n",
    "            key = (row['warehouse_id'], row['destination_zip3'], row['ship_method'])\n",
    "            if key in pad_dict.keys():\n",
    "                return pad_dict.get(key)\n",
    "            else:\n",
    "                key = (row['origin_zip3'], row['destination_zip3'], row['ship_method'])\n",
    "                if key in pad_dict.keys():\n",
    "                    return pad_dict.get(key)\n",
    "                \n",
    "\n",
    "\n",
    "    test_data['pad'] = test_data.apply(get_pad, axis=1)\n",
    "\n",
    "    padded_count = test_data['pad'].notna().sum()\n",
    "\n",
    "    total_entries = len(test_data)\n",
    "    percentage_padded = padded_count / total_entries * 100\n",
    "    print(f\"Percentage of shipments padded in testing period: {percentage_padded:.2f}%\")\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce074cd9-3129-426e-8a14-16bfa9810848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ModelPerformance(test_data, model_output): # read models and test on testing data\n",
    "\n",
    "    test_data['shipping_tracking'] = test_data['shipment_id'].astype('str') + test_data['tracking_id'].astype('str')    \n",
    "    test_data['unpadded_pdd_date'] = pd.to_datetime(test_data['unpadded_pdd_date'])\n",
    "    test_data['unpadded_pdd_dayofweek'] = test_data['unpadded_pdd_date'].dt.dayofweek\n",
    "    \n",
    "    test_data_with_pads = apply_pads(test_data.copy(), model_output.copy())\n",
    "    \n",
    "    print('Generating summary metrics by ship method...')\n",
    "    result_sm = metrics_ship_method(test_data_with_pads)\n",
    "    return result_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc980db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_weighted_average(result):\n",
    "    if result['Model Coverage'].dtype == object:\n",
    "        result['Model Coverage'] = result['Model Coverage'].astype(float)\n",
    "\n",
    "    # Check for other percentage columns that may include '%' characters\n",
    "    percentage_cols = ['Actual DEA (Optimized vol.)', 'Actual DEA (Non-optimized vol.)', 'UPRM DEA (Optimized vol.)', 'UPRM C2P (Optimized vol.)']\n",
    "    for col in percentage_cols:\n",
    "        if result[col].dtype == object:\n",
    "            if result[col].astype(str).str.contains('%').any():\n",
    "                result[col] = result[col].str.rstrip('%').astype(float) / 100\n",
    "            else:\n",
    "                result[col] = result[col].astype(float)\n",
    "\n",
    "    if result['Shipment Count'].dtype == object:\n",
    "        result['Shipment Count'] = result['Shipment Count'].replace(',', '').astype(int)\n",
    "\n",
    "    # Calculate weighted values for each category\n",
    "    result['weighted_dea_opt'] = result['UPRM DEA (Optimized vol.)'] * result['Model Coverage'] * result['Shipment Count']\n",
    "    result['weighted_c2p_opt'] = result['UPRM C2P (Optimized vol.)'] * result['Model Coverage'] * result['Shipment Count']\n",
    "    result['weighted_dea_non_opt'] = result['Actual DEA (Non-optimized vol.)'] * (1 - result['Model Coverage']) * result['Shipment Count']\n",
    "    result['weighted_c2p_non_opt'] = result['Actual C2P (Non-optimized vol.)'] * (1 - result['Model Coverage']) * result['Shipment Count']\n",
    "   \n",
    "    # Compute weighted averages for each row rather than aggregating first\n",
    "    result['Estimated DEA (Optimized+Non-optimized)'] = (result['weighted_dea_opt'] + result['weighted_dea_non_opt']) / result['Shipment Count']\n",
    "    result['Estimated C2P (Optimized+Non-optimized)'] = (result['weighted_c2p_opt'] + result['weighted_c2p_non_opt']) / result['Shipment Count']\n",
    "   \n",
    "    result = result.drop(columns=['weighted_dea_opt', 'weighted_c2p_opt', 'weighted_dea_non_opt', 'weighted_c2p_non_opt'])\n",
    "    return result\n",
    "\n",
    "\n",
    "def metrics_ship_method(test_data): \n",
    "    result = metrics(test_data)\n",
    "    ship_method = ['Overall']\n",
    "\n",
    "    \n",
    "    for sm in test_data['ship_method'].unique():\n",
    "        print(f\"Getting results for {sm}\")\n",
    "        test_data_s = test_data[test_data['ship_method'] == sm].copy()        \n",
    "        result_s = metrics(test_data_s)\n",
    "        result = pd.concat([result, result_s], axis = 0, ignore_index=True)\n",
    "        ship_method.append(sm)\n",
    "            \n",
    "    result.columns = ['Shipment Count', 'Model Coverage', 'Overall Actual C2P', 'Overall Actual Speed', 'Unpadded C2P (Optimized vol.)', 'Unpadded DEA (Optimized vol.)', 'Actual C2P (Optimized vol.)',\n",
    "                      'Actual DEA (Optimized vol.)', 'C2D', 'UPRM C2P (Optimized vol.)', 'UPRM DEA (Optimized vol.)', 'Unpadded C2P (Non-optimized vol.)',\n",
    "                      'Unpadded DEA (Non-optimized vol.)', 'Actual C2P (Non-optimized vol.)', 'Actual DEA (Non-optimized vol.)',\n",
    "                      'Pad %', 'TT Pad %', 'UTT Pad %']\n",
    "    result.index = ship_method\n",
    "    \n",
    "    ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
    "    ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n",
    "    result = pd.concat([result, ship_pct_f, ship_pct], axis = 1)\n",
    "    result.columns = ['Shipment Count', 'Model Coverage', 'Overall Actual DEA', 'Overall Actual C2P', 'Unpadded C2P (Optimized vol.)', 'Unpadded DEA (Optimized vol.)', 'Actual C2P (Optimized vol.)',\n",
    "                      'Actual DEA (Optimized vol.)', 'C2D', 'UPRM C2P (Optimized vol.)', 'UPRM DEA (Optimized vol.)', 'Unpadded C2P (Non-optimized vol.)',\n",
    "                      'Unpadded DEA (Non-optimized vol.)', 'Actual C2P (Non-optimized vol.)', 'Actual DEA (Non-optimized vol.)',\n",
    "                      'Pad %', 'TT Pad %', 'UTT Pad %', 'volume_share', 'volume_share_1']\n",
    "    result = result.sort_values(by = 'volume_share_1', ascending = False)\n",
    "    result = result.drop('volume_share_1', axis = 1)\n",
    "    \n",
    "    # Perform the weighted average calculations for net DEA and C2P\n",
    "    result = calculate_weighted_average(result)    \n",
    "    return result\n",
    "\n",
    "def metrics(test_data):\n",
    "    # get the overall speed and DEA\n",
    "    no_att_scan_overall = test_data.loc[test_data['no_att_scan'] == 'Y', 'shipping_tracking'].nunique()\n",
    "    shipments_overall = test_data['shipping_tracking'].nunique()\n",
    "    overall_speed = round((test_data['c2p_hours']/24).mean(), 2)      \n",
    "    att_failed_pdd_current_overall = test_data.loc[\n",
    "        (test_data['no_att_scan'] == 'N') &\n",
    "        (test_data['c2p_days'] < test_data['att_c2d_days']),  # Use c2p_days if it includes pad adjustments\n",
    "        'shipping_tracking'\n",
    "    ].nunique()\n",
    "    overall_dea = (\n",
    "        (shipments_overall - att_failed_pdd_current_overall - no_att_scan_overall) /\n",
    "        (shipments_overall - no_att_scan_overall)\n",
    "    ) if (shipments_overall - no_att_scan_overall) != 0 else None\n",
    "    overall_dea_formatted = '{:.2%}'.format(overall_dea) if overall_dea else None\n",
    "    \n",
    "    print(\"test_data shape: \", test_data.shape, \"len shipments_overall\", shipments_overall, overall_dea_formatted)\n",
    "\n",
    "    \n",
    "    test_data_model = test_data[test_data['pad'].notnull()].copy()\n",
    "    test_data_nomodel = test_data[test_data['pad'].isnull()].copy()\n",
    "    print(\"test_data_nomodel shape is:\" , test_data_nomodel.shape)\n",
    "        \n",
    "    model_coverage = round(test_data_model.shape[0]/test_data.shape[0], 2)\n",
    "    \n",
    "    shipment_cnt = test_data.shape[0]\n",
    "    \n",
    "    \n",
    "    ## shipment not covered by model ##\n",
    "    no_att_scan_nomodel = test_data_nomodel.loc[test_data_nomodel['no_att_scan'] == 'Y', 'shipping_tracking'].nunique()\n",
    "    shipments_nomodel = test_data_nomodel['shipping_tracking'].nunique()\n",
    " \n",
    "    unpadded_speed_nomodel = round((test_data_nomodel['c2p_hours_unpadded']/24).mean(),2)         \n",
    "    att_failed_pdd_unpadded_nomodel = test_data_nomodel.loc[(test_data_nomodel['no_att_scan'] == 'N') & (test_data_nomodel['c2p_days_unpadded'] < test_data_nomodel['att_c2d_days']), 'shipping_tracking'].nunique()    \n",
    "    unpadded_dea_nomodel = (shipments_nomodel- att_failed_pdd_unpadded_nomodel - no_att_scan_nomodel)/(shipments_nomodel-no_att_scan_nomodel) if shipments_nomodel-no_att_scan_nomodel !=0 else None    \n",
    "    unpadded_dea_nomodel = '{:.2%}'.format(unpadded_dea_nomodel) if unpadded_dea_nomodel else None\n",
    "    \n",
    "    \n",
    "    current_speed_nomodel = round((test_data_nomodel['c2p_hours']/24).mean(),2)      \n",
    "    att_failed_pdd_current_nomodel = test_data_nomodel.loc[test_data_nomodel['att_failed_pdd'] == 'Y', 'shipping_tracking'].nunique()\n",
    "    current_dea_nomodel = (shipments_nomodel- att_failed_pdd_current_nomodel - no_att_scan_nomodel)/(shipments_nomodel-no_att_scan_nomodel) if shipments_nomodel-no_att_scan_nomodel !=0 else None\n",
    "    current_dea_nomodel = '{:.2%}'.format(current_dea_nomodel) if current_dea_nomodel else None\n",
    "\n",
    "    \n",
    "    \n",
    "    if test_data_model.shape[0] >0:\n",
    "        print(\"test_data_model shape is:\" , test_data_model.shape)\n",
    "        test_data_model = schedule_adjust(test_data_model) # adjust pad for working day schedule\n",
    "    \n",
    "        no_att_scan = test_data_model.loc[test_data_model['no_att_scan'] == 'Y', 'shipping_tracking'].nunique()\n",
    "        shipments = test_data_model['shipping_tracking'].nunique()\n",
    " \n",
    "        unpadded_speed = round((test_data_model['c2p_hours_unpadded']/24).mean(),2)\n",
    "        c2d = round((test_data_model['c2d_hours']/24).mean(),2)\n",
    "    \n",
    "    \n",
    "        att_failed_pdd_unpadded = test_data_model.loc[(test_data_model['no_att_scan'] == 'N') & (test_data_model['c2p_days_unpadded'] < test_data_model['att_c2d_days']), 'shipping_tracking'].nunique()\n",
    "    \n",
    "        unpadded_dea = (shipments- att_failed_pdd_unpadded - no_att_scan)/(shipments-no_att_scan) if shipments-no_att_scan !=0 else None    \n",
    "\n",
    "        current_speed = round((test_data_model['c2p_hours']/24).mean(),2)   \n",
    "\n",
    "   \n",
    "        att_failed_pdd_current = test_data_model.loc[test_data_model['att_failed_pdd'] == 'Y', 'shipping_tracking'].nunique()\n",
    "        current_dea = (shipments- att_failed_pdd_current - no_att_scan)/(shipments-no_att_scan) if shipments-no_att_scan !=0 else None\n",
    "    \n",
    "        current_efficiency =  round((current_dea - unpadded_dea)*100/(current_speed - unpadded_speed), 2) if current_speed and unpadded_speed and current_dea and unpadded_dea and current_speed - unpadded_speed !=0 else None\n",
    "        #current_efficiency_2 =  round(((current_dea - unpadded_dea)/unpadded_dea)/((current_speed - unpadded_speed)/unpadded_speed), 2) if current_speed - unpadded_speed !=0 else None\n",
    "    \n",
    "        current_dea = '{:.2%}'.format(current_dea) if current_dea else None\n",
    "\n",
    "        new_speed = round(((test_data_model['c2p_hours_unpadded'] + test_data_model['adjusted_pad'] * 24)/24).mean(),2)\n",
    "        att_failed_pdd_new = test_data_model.loc[(test_data_model['no_att_scan'] == 'N') & (test_data_model['c2p_days_unpadded'] + test_data_model['adjusted_pad'] < test_data_model['att_c2d_days']), 'shipping_tracking'].nunique()\n",
    "        new_dea = (shipments- att_failed_pdd_new - no_att_scan)/(shipments-no_att_scan) if (shipments-no_att_scan) !=0 else None\n",
    "        new_efficiency = round((new_dea - unpadded_dea)*100/(new_speed - unpadded_speed), 2) if new_speed and unpadded_speed and new_dea and unpadded_dea and new_speed - unpadded_speed !=0 else None\n",
    "        #new_efficiency_2 =  round(((new_dea - unpadded_dea)/unpadded_dea)/((new_speed - unpadded_speed)/unpadded_speed), 2) if new_speed - unpadded_speed !=0 and new_dea and unpadded_dea else None\n",
    "\n",
    "    \n",
    "        new_dea = '{:.2%}'.format(new_dea) if new_dea else None\n",
    "    \n",
    "        unpadded_dea = '{:.2%}'.format(unpadded_dea) if unpadded_dea else None\n",
    "    \n",
    "        padded_pct = '{:.2%}'.format(test_data_model[test_data_model['adjusted_pad'] !=0].shape[0]/test_data_model.shape[0] if test_data_model.shape[0] >0 else None)\n",
    "    \n",
    "        padded_pct_noswa = '{:.2%}'.format(test_data_model[(test_data_model['adjusted_pad'] !=0) & (test_data_model['ship_method'] != 'SWA')].shape[0]/test_data_model.shape[0] if test_data_model.shape[0]>0 else None)\n",
    "        padded_pct_swa = '{:.2%}'.format(test_data_model[(test_data_model['adjusted_pad'] !=0) & (test_data_model['ship_method'] == 'SWA')].shape[0]/test_data_model.shape[0] if test_data_model.shape[0] >0 else None)  \n",
    "    \n",
    "        # speed and dea by ups and swa    \n",
    "        test_ups = test_data_model[test_data_model['ship_method'].isin(['UPS_GROUND', 'UPS_NEXT_DAY', 'UPS_2ND_DAY', 'UPS_3_DAY'])].copy()\n",
    "        test_swa = test_data_model[test_data_model['ship_method'].isin(['SWA'])].copy()\n",
    "    \n",
    "        shipments_ups = test_ups['shipping_tracking'].nunique()\n",
    "        new_speed_ups = round(((test_ups['c2p_hours_unpadded'] + test_ups['adjusted_pad'] * 24)/24).mean(),2)\n",
    "        att_failed_pdd_new_ups = test_ups.loc[(test_ups['no_att_scan'] == 'N') & (test_ups['c2p_days_unpadded'] + test_ups['adjusted_pad'] < test_ups['att_c2d_days']), 'shipping_tracking'].nunique()\n",
    "        no_att_scan_ups = test_ups.loc[test_ups['no_att_scan'] == 'Y', 'shipping_tracking'].nunique()\n",
    "        new_dea_ups = (shipments_ups- att_failed_pdd_new_ups - no_att_scan_ups)/(shipments_ups-no_att_scan_ups) if (shipments_ups-no_att_scan_ups) !=0 else None   \n",
    "        new_dea_ups = '{:.2%}'.format(new_dea_ups) if new_dea_ups else None    \n",
    "    \n",
    "        shipments_swa = test_swa['shipping_tracking'].nunique()\n",
    "        new_speed_swa = round(((test_swa['c2p_hours_unpadded'] + test_swa['adjusted_pad'] * 24)/24).mean(),2)\n",
    "        att_failed_pdd_new_swa = test_swa.loc[(test_swa['no_att_scan'] == 'N') & (test_swa['c2p_days_unpadded'] + test_swa['adjusted_pad'] < test_swa['att_c2d_days']), 'shipping_tracking'].nunique()\n",
    "        no_att_scan_swa = test_swa.loc[test_swa['no_att_scan'] == 'Y', 'shipping_tracking'].nunique()\n",
    "        new_dea_swa = (shipments_swa - att_failed_pdd_new_swa - no_att_scan_swa)/(shipments_swa-no_att_scan_swa) if (shipments_swa-no_att_scan_swa) !=0 else None\n",
    "        new_dea_swa = '{:.2%}'.format(new_dea_swa) if new_dea_swa else None\n",
    "    \n",
    "\n",
    "        result = pd.DataFrame([shipment_cnt, model_coverage, overall_speed, overall_dea_formatted, unpadded_speed, unpadded_dea, current_speed, current_dea, c2d, new_speed, new_dea, unpadded_speed_nomodel, unpadded_dea_nomodel, current_speed_nomodel, current_dea_nomodel, padded_pct, padded_pct_noswa, padded_pct_swa]).T\n",
    "    else:\n",
    "        result = pd.DataFrame([None] * 16 + [shipment_cnt, model_coverage, unpadded_speed_nomodel, unpadded_dea_nomodel, current_speed_nomodel, current_dea_nomodel]).T\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582a2dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/fsspec/registry.py:273: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape is:  (2013387, 38)\n"
     ]
    }
   ],
   "source": [
    "date = '20240301'\n",
    "test_data_0301 = ReadTestData(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2d5bdf-9f0d-428f-8786-eba2a5de14ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_93per_88perc1P_AIRDEA0.94_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    304391\n",
      " 1.0     71923\n",
      "-1.0     32257\n",
      " 2.0      8856\n",
      "-2.0      4950\n",
      "-3.0      1301\n",
      " 3.0      1207\n",
      " 4.0       153\n",
      " 5.0        38\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_93per_88perc1P_AIRDEA0.94_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    342901\n",
      "1.0     71923\n",
      "2.0      8856\n",
      "3.0      1207\n",
      "4.0       153\n",
      "5.0        38\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_93per_88perc1P_AIRDEA0.94_AMXLExcluded.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_93per_90perc1P_AIRDEA0.9_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    322149\n",
      " 1.0     55569\n",
      "-1.0     32339\n",
      " 2.0      7512\n",
      "-2.0      4961\n",
      "-3.0      1303\n",
      " 3.0      1080\n",
      " 4.0       128\n",
      " 5.0        35\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_93per_90perc1P_AIRDEA0.9_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    360754\n",
      "1.0     55569\n",
      "2.0      7512\n",
      "3.0      1080\n",
      "4.0       128\n",
      "5.0        35\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_93per_90perc1P_AIRDEA0.9_AMXLExcluded.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_95per_86perc1P_AIRDEA0.88_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    285315\n",
      " 1.0     80262\n",
      "-1.0     32196\n",
      " 2.0     16163\n",
      "-2.0      5506\n",
      " 3.0      3168\n",
      "-3.0      1757\n",
      " 4.0       585\n",
      " 5.0       124\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_95per_86perc1P_AIRDEA0.88_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    324776\n",
      "1.0     80262\n",
      "2.0     16163\n",
      "3.0      3168\n",
      "4.0       585\n",
      "5.0       124\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_95per_86perc1P_AIRDEA0.88_AMXLExcluded.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_95per_86perc1P_AIRDEA0.93_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    274657\n",
      " 1.0     90862\n",
      "-1.0     30890\n",
      " 2.0     18142\n",
      "-2.0      4818\n",
      " 3.0      3637\n",
      "-3.0      1273\n",
      " 4.0       658\n",
      " 5.0       139\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_95per_86perc1P_AIRDEA0.93_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    311640\n",
      "1.0     90862\n",
      "2.0     18142\n",
      "3.0      3637\n",
      "4.0       658\n",
      "5.0       139\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_95per_86perc1P_AIRDEA0.93_AMXLExcluded.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_95per_86perc1P_AIRDEA0.9_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    285199\n",
      " 1.0     81819\n",
      "-1.0     30972\n",
      " 2.0     16754\n",
      "-2.0      4831\n",
      " 3.0      3464\n",
      "-3.0      1275\n",
      " 4.0       628\n",
      " 5.0       134\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_95per_86perc1P_AIRDEA0.9_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    322279\n",
      "1.0     81819\n",
      "2.0     16754\n",
      "3.0      3464\n",
      "4.0       628\n",
      "5.0       134\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_95per_86perc1P_AIRDEA0.9_AMXLExcluded.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_95per_88perc1P_AIRDEA0.9_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    285413\n",
      " 1.0     81448\n",
      "-1.0     30973\n",
      " 2.0     16872\n",
      "-2.0      4833\n",
      " 3.0      3497\n",
      "-3.0      1275\n",
      " 4.0       630\n",
      " 5.0       135\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_95per_88perc1P_AIRDEA0.9_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    322496\n",
      "1.0     81448\n",
      "2.0     16872\n",
      "3.0      3497\n",
      "4.0       630\n",
      "5.0       135\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_95per_88perc1P_AIRDEA0.9_AMXLExcluded.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_95per_90perc1P_AIRDEA0.90_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    288287\n",
      " 1.0     78218\n",
      "-1.0     30478\n",
      " 2.0     17638\n",
      "-2.0      4811\n",
      " 3.0      3594\n",
      "-3.0      1270\n",
      " 4.0       641\n",
      " 5.0       139\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_95per_90perc1P_AIRDEA0.90_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    324848\n",
      "1.0     78218\n",
      "2.0     17638\n",
      "3.0      3594\n",
      "4.0       641\n",
      "5.0       139\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_95per_90perc1P_AIRDEA0.90_AMXLExcluded.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/3702636474.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  model = pd.read_csv(f\"{path}{file_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding distribution before change for NEW_MODEL_feb_96per_86perc1P_AIRDEA0.93_AMXLExcluded.csv:\n",
      "pad\n",
      " 0.0    259723\n",
      " 1.0     96322\n",
      "-1.0     28465\n",
      " 2.0     24099\n",
      " 3.0      7760\n",
      "-2.0      4547\n",
      " 4.0      2175\n",
      "-3.0      1227\n",
      " 5.0       758\n",
      "-1.5         1\n",
      "-0.5         1\n",
      "Name: count, dtype: int64\n",
      "Padding distribution after change for NEW_MODEL_feb_96per_86perc1P_AIRDEA0.93_AMXLExcluded.csv:\n",
      "pad\n",
      "0.0    293964\n",
      "1.0     96322\n",
      "2.0     24099\n",
      "3.0      7760\n",
      "4.0      2175\n",
      "5.0       758\n",
      "Name: count, dtype: int64\n",
      "Percentage of shipments padded in testing period: 82.89%\n",
      "Generating summary metrics by ship method...\n",
      "test_data shape:  (2013387, 41) len shipments_overall 2012208 93.50%\n",
      "test_data_nomodel shape is: (344560, 41)\n",
      "test_data_model shape is: (1668827, 41)\n",
      "Getting results for SWA\n",
      "test_data shape:  (409977, 41) len shipments_overall 409977 89.24%\n",
      "test_data_nomodel shape is: (295, 41)\n",
      "test_data_model shape is: (409682, 41)\n",
      "Getting results for UPS_GROUND\n",
      "test_data shape:  (1288253, 41) len shipments_overall 1287540 95.02%\n",
      "test_data_nomodel shape is: (218968, 41)\n",
      "test_data_model shape is: (1069285, 41)\n",
      "Getting results for UPS_2ND_DAY\n",
      "test_data shape:  (251676, 41) len shipments_overall 251265 93.70%\n",
      "test_data_nomodel shape is: (91401, 41)\n",
      "test_data_model shape is: (160275, 41)\n",
      "Getting results for UPS_NEXT_DAY\n",
      "test_data shape:  (63481, 41) len shipments_overall 63426 89.68%\n",
      "test_data_nomodel shape is: (33896, 41)\n",
      "test_data_model shape is: (29585, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64022/2488935193.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct = test_data.groupby('ship_method').apply(lambda x: x.shape[0]/test_data.shape[0])\n",
      "/tmp/ipykernel_64022/2488935193.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ship_pct_f = test_data.groupby('ship_method').apply(lambda x: '{:.2%}'.format(x.shape[0]/test_data.shape[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./Feb_analysis/result_NEW_MODEL_feb_96per_86perc1P_AIRDEA0.93_AMXLExcluded.csv\n"
     ]
    }
   ],
   "source": [
    "path = \"./Feb_analysis/\"\n",
    "file_names = [\n",
    "    \"NEW_MODEL_feb_93per_88perc1P_AIRDEA0.94_AMXLExcluded.csv\",\n",
    "    \"NEW_MODEL_feb_93per_90perc1P_AIRDEA0.9_AMXLExcluded.csv\",\n",
    "    \"NEW_MODEL_feb_95per_86perc1P_AIRDEA0.88_AMXLExcluded.csv\",\n",
    "    \"NEW_MODEL_feb_95per_86perc1P_AIRDEA0.93_AMXLExcluded.csv\",\n",
    "    \"NEW_MODEL_feb_95per_86perc1P_AIRDEA0.9_AMXLExcluded.csv\",\n",
    "    \"NEW_MODEL_feb_95per_88perc1P_AIRDEA0.9_AMXLExcluded.csv\",\n",
    "    \"NEW_MODEL_feb_95per_90perc1P_AIRDEA0.90_AMXLExcluded.csv\",\n",
    "    \"NEW_MODEL_feb_96per_86perc1P_AIRDEA0.93_AMXLExcluded.csv\"\n",
    "]\n",
    "\n",
    "def ReadSolverModel(file_name):\n",
    "    model = pd.read_csv(f\"{path}{file_name}\")\n",
    "    model['origin'] = model['Warehouse']\n",
    "    model['destination_zip3'] = model['Destination ZIP3'].astype(str)\n",
    "    model['ship_method'] = model['Ship Method']\n",
    "    model.rename(columns={'Pad': 'pad'}, inplace=True)\n",
    "    model = model[['wh_ind', 'origin', 'destination_zip3', 'ship_method', 'pad']]\n",
    "    # Overwrite negative padding from the model with 0 days\n",
    "    print(f\"Padding distribution before change for {file_name}:\")\n",
    "    print(model['pad'].value_counts())\n",
    "    model['pad'] = model['pad'].apply(lambda x: 0 if x < 0 else x)\n",
    "    print(f\"Padding distribution after change for {file_name}:\")\n",
    "    print(model['pad'].value_counts())\n",
    "    return model\n",
    "\n",
    "for file_name in file_names:\n",
    "    model_data = ReadSolverModel(file_name)\n",
    "    result = ModelPerformance(test_data_0301, model_data)  # Ensure test_data_0301 is defined or passed correctly\n",
    "   \n",
    "    result_output_path = os.path.join(path, f\"result_{file_name}\")\n",
    "    result.to_csv(result_output_path, index=False)\n",
    "    print(f\"Results saved to {result_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3839182-ea33-46fe-ad8e-33fc9b84552e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shipment Count</th>\n",
       "      <th>Model Coverage</th>\n",
       "      <th>Overall Actual DEA</th>\n",
       "      <th>Overall Actual C2P</th>\n",
       "      <th>Unpadded C2P (Optimized vol.)</th>\n",
       "      <th>Unpadded DEA (Optimized vol.)</th>\n",
       "      <th>Actual C2P (Optimized vol.)</th>\n",
       "      <th>Actual DEA (Optimized vol.)</th>\n",
       "      <th>C2D</th>\n",
       "      <th>UPRM C2P (Optimized vol.)</th>\n",
       "      <th>UPRM DEA (Optimized vol.)</th>\n",
       "      <th>Unpadded C2P (Non-optimized vol.)</th>\n",
       "      <th>Unpadded DEA (Non-optimized vol.)</th>\n",
       "      <th>Actual C2P (Non-optimized vol.)</th>\n",
       "      <th>Actual DEA (Non-optimized vol.)</th>\n",
       "      <th>Pad %</th>\n",
       "      <th>TT Pad %</th>\n",
       "      <th>UTT Pad %</th>\n",
       "      <th>volume_share</th>\n",
       "      <th>Estimated DEA (Optimized+Non-optimized)</th>\n",
       "      <th>Estimated C2P (Optimized+Non-optimized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UPS_GROUND</th>\n",
       "      <td>1288253</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.49</td>\n",
       "      <td>95.02%</td>\n",
       "      <td>6.65</td>\n",
       "      <td>91.39%</td>\n",
       "      <td>7.36</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>4.43</td>\n",
       "      <td>7.51</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>7.41</td>\n",
       "      <td>90.12%</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>41.02%</td>\n",
       "      <td>41.02%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>63.98%</td>\n",
       "      <td>0.956790</td>\n",
       "      <td>7.6137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWA</th>\n",
       "      <td>409977</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.68</td>\n",
       "      <td>89.24%</td>\n",
       "      <td>7.41</td>\n",
       "      <td>86.68%</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>5.93</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>6.36</td>\n",
       "      <td>73.50%</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>18.69%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>18.69%</td>\n",
       "      <td>20.36%</td>\n",
       "      <td>0.893900</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPS_2ND_DAY</th>\n",
       "      <td>251676</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.59</td>\n",
       "      <td>93.70%</td>\n",
       "      <td>5.35</td>\n",
       "      <td>91.14%</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>3.94</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.9329</td>\n",
       "      <td>5.18</td>\n",
       "      <td>89.69%</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>16.18%</td>\n",
       "      <td>16.18%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>0.930992</td>\n",
       "      <td>5.5224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPS_NEXT_DAY</th>\n",
       "      <td>63481</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.25</td>\n",
       "      <td>89.68%</td>\n",
       "      <td>4.07</td>\n",
       "      <td>88.64%</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>2.73</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>3.97</td>\n",
       "      <td>85.43%</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>18.09%</td>\n",
       "      <td>18.09%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>3.15%</td>\n",
       "      <td>0.895884</td>\n",
       "      <td>4.2552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>2013387</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.19</td>\n",
       "      <td>93.50%</td>\n",
       "      <td>6.67</td>\n",
       "      <td>90.15%</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>4.72</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.9396</td>\n",
       "      <td>6.48</td>\n",
       "      <td>89.53%</td>\n",
       "      <td>7.01</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>32.74%</td>\n",
       "      <td>28.16%</td>\n",
       "      <td>4.59%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938699</td>\n",
       "      <td>7.2424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Shipment Count  Model Coverage Overall Actual DEA  \\\n",
       "UPS_GROUND           1288253            0.83               7.49   \n",
       "SWA                   409977            1.00               7.68   \n",
       "UPS_2ND_DAY           251676            0.64               5.59   \n",
       "UPS_NEXT_DAY           63481            0.47               4.25   \n",
       "Overall              2013387            0.83               7.19   \n",
       "\n",
       "             Overall Actual C2P Unpadded C2P (Optimized vol.)  \\\n",
       "UPS_GROUND               95.02%                          6.65   \n",
       "SWA                      89.24%                          7.41   \n",
       "UPS_2ND_DAY              93.70%                          5.35   \n",
       "UPS_NEXT_DAY             89.68%                          4.07   \n",
       "Overall                  93.50%                          6.67   \n",
       "\n",
       "             Unpadded DEA (Optimized vol.) Actual C2P (Optimized vol.)  \\\n",
       "UPS_GROUND                          91.39%                        7.36   \n",
       "SWA                                 86.68%                        7.68   \n",
       "UPS_2ND_DAY                         91.14%                        5.69   \n",
       "UPS_NEXT_DAY                        88.64%                        4.33   \n",
       "Overall                             90.15%                        7.23   \n",
       "\n",
       "              Actual DEA (Optimized vol.)   C2D  UPRM C2P (Optimized vol.)  \\\n",
       "UPS_GROUND                         0.9510  4.43                       7.51   \n",
       "SWA                                0.8925  5.93                       7.60   \n",
       "UPS_2ND_DAY                        0.9422  3.94                       5.58   \n",
       "UPS_NEXT_DAY                       0.9174  2.73                       4.34   \n",
       "Overall                            0.9351  4.72                       7.29   \n",
       "\n",
       "              UPRM DEA (Optimized vol.) Unpadded C2P (Non-optimized vol.)  \\\n",
       "UPS_GROUND                       0.9590                              7.41   \n",
       "SWA                              0.8939                              6.36   \n",
       "UPS_2ND_DAY                      0.9329                              5.18   \n",
       "UPS_NEXT_DAY                     0.9156                              3.97   \n",
       "Overall                          0.9396                              6.48   \n",
       "\n",
       "             Unpadded DEA (Non-optimized vol.)  \\\n",
       "UPS_GROUND                              90.12%   \n",
       "SWA                                     73.50%   \n",
       "UPS_2ND_DAY                             89.69%   \n",
       "UPS_NEXT_DAY                            85.43%   \n",
       "Overall                                 89.53%   \n",
       "\n",
       "             Actual C2P (Non-optimized vol.)  Actual DEA (Non-optimized vol.)  \\\n",
       "UPS_GROUND                              8.12                           0.9460   \n",
       "SWA                                     6.36                           0.7350   \n",
       "UPS_2ND_DAY                             5.42                           0.9276   \n",
       "UPS_NEXT_DAY                            4.18                           0.8784   \n",
       "Overall                                 7.01                           0.9343   \n",
       "\n",
       "               Pad % TT Pad % UTT Pad % volume_share  \\\n",
       "UPS_GROUND    41.02%   41.02%     0.00%       63.98%   \n",
       "SWA           18.69%    0.00%    18.69%       20.36%   \n",
       "UPS_2ND_DAY   16.18%   16.18%     0.00%       12.50%   \n",
       "UPS_NEXT_DAY  18.09%   18.09%     0.00%        3.15%   \n",
       "Overall       32.74%   28.16%     4.59%          NaN   \n",
       "\n",
       "              Estimated DEA (Optimized+Non-optimized)  \\\n",
       "UPS_GROUND                                   0.956790   \n",
       "SWA                                          0.893900   \n",
       "UPS_2ND_DAY                                  0.930992   \n",
       "UPS_NEXT_DAY                                 0.895884   \n",
       "Overall                                      0.938699   \n",
       "\n",
       "             Estimated C2P (Optimized+Non-optimized)  \n",
       "UPS_GROUND                                    7.6137  \n",
       "SWA                                              7.6  \n",
       "UPS_2ND_DAY                                   5.5224  \n",
       "UPS_NEXT_DAY                                  4.2552  \n",
       "Overall                                       7.2424  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20eaa6-b72c-4937-b67e-3bc17a3ebbce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
